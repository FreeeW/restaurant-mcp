// Avoid framework-specific types here to keep it portable in Vercel Node runtime
let openaiClient: any = null;
import { spawn, ChildProcess } from 'node:child_process';
import { Client as MCPClient } from '@modelcontextprotocol/sdk/client/index.js';
import { StdioClientTransport } from '@modelcontextprotocol/sdk/client/stdio.js';
import { existsSync } from 'node:fs';

async function getOpenAI() {
  if (openaiClient) return openaiClient;
  // @ts-ignore - dynamic import; types resolved at runtime in Vercel
  const mod: any = await import('openai');
  const OpenAI = mod.default || mod;
  openaiClient = new OpenAI({ apiKey: process.env.OPENAI_API_KEY! });
  console.log('[gateway] OpenAI client initialized', { model: process.env.OPENAI_MODEL || 'gpt-4o-mini' });
  return openaiClient;
}

let mcpClient: MCPClient | null = null;
let mcpTools: Array<{ name: string; description?: string; inputSchema?: any }> = [];
let lastDebug: any = {};
let mcpProc: ChildProcess | null = null;
let mcpReady = false;

async function ensureMcp() {
  if (mcpClient) return;
  // Spawn the prebuilt MCP server (generated by `npm run build`)
  console.log('[gateway][mcp] ensure start', {
    hasSbUrl: !!process.env.SUPABASE_URL,
    hasSbKey: !!process.env.SUPABASE_SERVICE_ROLE_KEY,
  });
  console.log('[gateway] starting MCP process…');
  const mcpPath = 'dist/src/index.js';
  console.log('[gateway][mcp] checking path', { mcpPath, exists: existsSync(mcpPath) });
  if (!existsSync(mcpPath)) {
    throw new Error(`MCP server not found at ${mcpPath}. Build may have failed.`);
  }
  const proc = spawn('node', [mcpPath], {
    stdio: ['pipe', 'pipe', 'inherit'],
    env: process.env,
  });
  mcpProc = proc;
  proc.on('spawn', () => console.log('[gateway][mcp] spawned', { pid: proc.pid }));
  proc.on('exit', (code, signal) => console.error('[gateway][mcp] exit', { code, signal }));
  proc.on('error', (err) => console.error('[gateway][mcp] error', { message: err?.message }));
  proc.stdout?.on('data', (buf) => {
    try {
      const msg = buf.toString();
      console.log('[gateway][mcp][stdout]', msg.slice(0, 300));
    } catch {}
  });
  const transport = new StdioClientTransport({
    stdin: proc.stdin!,
    stdout: proc.stdout!,
  } as any);
  mcpClient = new MCPClient({ name: 'gateway', version: '0.1.0' });
  await mcpClient.connect(transport);
  const listed = await mcpClient.listTools();
  mcpTools = (listed?.tools ?? []) as any[];
  try {
    console.log('[gateway] MCP tools loaded:', mcpTools.map((t: any) => t.name));
  } catch {}
  console.log('[gateway][mcp] connected');
  mcpReady = true;
}

function toOpenAITools(tools: typeof mcpTools) {
  return tools.map((t) => ({
    type: 'function' as const,
    function: {
      name: t.name,
      description: t.description ?? '',
      parameters: t.inputSchema ?? { type: 'object', properties: {}, additionalProperties: true },
    },
  }));
}

async function runChat(owner_id: string, text: string): Promise<string> {
  await ensureMcp();

  const tools = toOpenAITools(mcpTools);
  const system = `Você é um assistente que usa ferramentas MCP. Sempre inclua "owner_id":"${owner_id}" nos argumentos das ferramentas quando necessário. Responda em pt-BR.`;

  const messages: any[] = [
    { role: 'system', content: system },
    { role: 'user', content: text },
  ];

  for (let iter = 0; iter < 6; iter++) {
    const openai = await getOpenAI();
    const forceDaily = /\\bforce:get_daily_kpi_on_date\\b/i.test(text);
    console.log('[gateway] openai.chat.completions.create', { iter, forceDaily, toolsCount: tools.length });
    lastDebug = { ...(lastDebug || {}), iter, forceDaily, toolsCount: tools.length, ts: Date.now() };
    const resp = await openai.chat.completions.create({
      model: process.env.OPENAI_MODEL || 'gpt-4o-mini',
      messages,
      tools,
      tool_choice: forceDaily ? { type: 'function', function: { name: 'get_daily_kpi_on_date' } } : 'required',
      temperature: 0.2,
    });

    const msg = resp.choices[0]?.message;
    if (!msg) return 'Erro temporário. Tente novamente.';

    const toolCalls = msg.tool_calls ?? [];
    try {
      console.log('[gateway] model response', { hasToolCalls: !!toolCalls.length, preview: String(msg.content || '').slice(0, 80) });
      if (toolCalls.length) console.log('[gateway] tool_calls:', toolCalls.map((t: any) => t.function?.name));
      lastDebug = { ...(lastDebug || {}), hasToolCalls: !!toolCalls.length, toolCalls: toolCalls.map((t: any) => t.function?.name), preview: String(msg.content || '').slice(0, 80) };
    } catch {}
    if (!toolCalls.length) {
      const final = msg.content?.toString().trim() || 'Ok.';
      return final;
    }

    for (const tc of toolCalls) {
      const name = tc.function?.name || '';
      const argsText = tc.function?.arguments || '{}';
      let args: any = {};
      try { args = JSON.parse(argsText); } catch {}
      if (owner_id && (args && typeof args === 'object')) args.owner_id ??= owner_id;

      console.log('[gateway] callTool precheck', {
        mcpReady,
        pid: mcpProc?.pid,
        exited: (mcpProc as any)?.exitCode != null,
      });
      try {
        console.log('[gateway] callTool', { name, args });
        const result = await mcpClient!.callTool({ name, arguments: args });
        try {
          console.log('[gateway] tool_result', { name, isError: !!result?.isError, hasStructured: !!result?.structuredContent });
          const prev = Array.isArray((lastDebug || {}).results) ? lastDebug.results : [];
          lastDebug = { ...(lastDebug || {}), results: [...prev, { name, isError: !!result?.isError, hasStructured: !!result?.structuredContent }] };
        } catch {}
        messages.push({
          role: 'tool',
          tool_call_id: tc.id,
          content: JSON.stringify(result?.structuredContent ?? result ?? {}),
        } as any);
      } catch (err: any) {
        console.error('[gateway][callTool_error]', {
          name,
          errMsg: err?.message || String(err),
          stack: err?.stack?.slice(0, 500),
          mcpReady,
          pid: mcpProc?.pid,
          exitCode: (mcpProc as any)?.exitCode,
          signalCode: (mcpProc as any)?.signalCode,
        });
        throw err;
      }
    }

    messages.push({ role: 'assistant', content: msg.content ?? '', tool_calls: msg.tool_calls as any });
  }

  return 'Não consegui concluir a operação com ferramentas. Tente novamente.';
}

export default async function handler(req: any, res: any) {
  try {
    if (req.method !== 'POST') return res.status(405).json({ error: 'method_not_allowed' });

    const expected = process.env.AI_GATEWAY_TOKEN ?? process.env.GATEWAY_SECRET;
    if (expected) {
      const got = (req.headers.authorization || '').replace(/^Bearer\s+/i, '');
      if (!got || got !== expected) return res.status(401).json({ error: 'unauthorized' });
    }

    const { owner_id, from, text } = (req.body || {}) as { owner_id?: string; from?: string; text?: string };
    if (!owner_id || !text) return res.status(400).json({ error: 'missing_owner_id_or_text' });
    if (!process.env.OPENAI_API_KEY) return res.status(500).json({ error: 'missing_openai_key' });

    const reply = await runChat(owner_id, text);
    return res.status(200).json({ reply });
  } catch (e: any) {
    console.error('gateway_error', e?.message || e);
    return res.status(500).json({ error: 'gateway_error' });
  }
}


